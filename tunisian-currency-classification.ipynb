{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":4313434,"sourceType":"datasetVersion","datasetId":2540038},{"sourceId":9702831,"sourceType":"datasetVersion","datasetId":5933716},{"sourceId":9703039,"sourceType":"datasetVersion","datasetId":5933876}],"dockerImageVersionId":30786,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Title: Image Classification Using Transfer Learning with VGG16**\n# \n**Objective**:\nThe primary goal of this project is to develop a robust image classification model leveraging transfer learning techniques. By utilizing the pre-trained VGG16 architecture, we aim to achieve high accuracy in classifying images into distinct categories. This approach significantly reduces the time required for training and allows us to benefit from the learned features of a model that has already been trained on a vast dataset (ImageNet).\n\n**Background**:\nImage classification is a fundamental task in computer vision, where the objective is to assign a label from a predefined set of categories to an input image. Traditional methods require extensive computational resources and large datasets to achieve acceptable performance. However, with the advent of transfer learning, it is now possible to fine-tune existing models on specific tasks with relatively smaller datasets. VGG16, known for its depth and architecture, serves as a powerful base model for transfer learning applications.\n\n**Methodology**:\nThis project involves the following key steps:\n\n**1. Data Preparation**: Loading and preprocessing the dataset for training and validation.\n\n**2. Model Selection**: Choosing the VGG16 architecture and modifying it to fit our specific classification task.\n\n**3. Training the Model**: Training the model on the prepared dataset while applying data augmentation to enhance generalization.\n\n**4. Evaluation**: Assessing the model’s performance using accuracy metrics and validation loss.\n","metadata":{}},{"cell_type":"markdown","source":"# **1-Data Preparation**","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-23T13:57:34.987165Z","iopub.execute_input":"2024-10-23T13:57:34.988133Z","iopub.status.idle":"2024-10-23T13:57:35.020838Z","shell.execute_reply.started":"2024-10-23T13:57:34.988081Z","shell.execute_reply":"2024-10-23T13:57:35.019571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 1. Importation des bibliothèques\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\nfrom PIL import Image\n\n# 2. Définition des chemins et catégories\ndataset_path = \"/kaggle/input/tunisian-currency\"  # Chemin vers votre dataset\ncategories = [\"5dt\", \"10dt\", \"20Dt\", \"50dt\"]  # Catégories (noms des dossiers)\n\n# 3. Résumé du dataset\ndef dataset_summary():\n    for category in categories:\n        folder_path = os.path.join(dataset_path, category)\n        num_images = len(os.listdir(folder_path))\n        print(f\"{category}: {num_images} images\")\n\n# Afficher le nombre d'images par classe\ndataset_summary()\n\n","metadata":{"execution":{"iopub.status.busy":"2024-10-23T13:36:28.748846Z","iopub.execute_input":"2024-10-23T13:36:28.749417Z","iopub.status.idle":"2024-10-23T13:37:05.441484Z","shell.execute_reply.started":"2024-10-23T13:36:28.749360Z","shell.execute_reply":"2024-10-23T13:37:05.439973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 4. Visualisation d'échantillons d'images\nimage_size = (128, 128)\n\ndef plot_sample_images():\n    plt.figure(figsize=(12, 12))\n    for i, category in enumerate(categories):\n        folder_path = os.path.join(dataset_path, category)\n        image_files = os.listdir(folder_path)[:5]  # Charger les 5 premières images\n        for j, image_name in enumerate(image_files):\n            img_path = os.path.join(folder_path, image_name)\n            img = load_img(img_path, target_size=image_size)\n            img_array = img_to_array(img) / 255.0  # Normalisation\n            plt.subplot(len(categories), 5, i * 5 + j + 1)\n            plt.imshow(img_array)\n            plt.axis('off')\n            plt.title(category)\n    plt.tight_layout()\n    plt.show()\n\n# Afficher les échantillons d'images\nplot_sample_images()\n\n","metadata":{"execution":{"iopub.status.busy":"2024-10-23T13:57:45.090042Z","iopub.execute_input":"2024-10-23T13:57:45.091238Z","iopub.status.idle":"2024-10-23T13:57:48.742241Z","shell.execute_reply.started":"2024-10-23T13:57:45.091180Z","shell.execute_reply":"2024-10-23T13:57:48.740247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 5. Vérification des tailles d'image\ndef check_image_sizes():\n    for category in categories:\n        folder_path = os.path.join(dataset_path, category)\n        image_files = os.listdir(folder_path)[:5]  # Charger les 5 premières images\n        print(f\"Checking image sizes in category {category}:\")\n        for image_name in image_files:\n            img_path = os.path.join(folder_path, image_name)\n            img = Image.open(img_path)\n            print(f\"Image {image_name}: {img.size}\")\n\n# Vérifier les dimensions des images\ncheck_image_sizes()\n\n","metadata":{"execution":{"iopub.status.busy":"2024-10-23T13:58:35.936511Z","iopub.execute_input":"2024-10-23T13:58:35.937071Z","iopub.status.idle":"2024-10-23T13:58:35.999495Z","shell.execute_reply.started":"2024-10-23T13:58:35.937018Z","shell.execute_reply":"2024-10-23T13:58:35.998228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 6. Histogrammes de couleur pour une image exemple\ndef plot_color_histogram(image_path):\n    img = load_img(image_path, target_size=image_size)\n    img_array = img_to_array(img).astype(np.uint8)\n\n    plt.figure(figsize=(8, 4))\n    for i, color in enumerate([\"Red\", \"Green\", \"Blue\"]):\n        plt.subplot(1, 3, i + 1)\n        plt.hist(img_array[:, :, i].ravel(), bins=256, color=color.lower(), alpha=0.8)\n        plt.title(f'{color} Histogram')\n    plt.tight_layout()\n    plt.show()\n\n# Exemple avec une image\nexample_image_path = os.path.join(dataset_path, \"10dt\", os.listdir(os.path.join(dataset_path, \"10dt\"))[0])\nplot_color_histogram(example_image_path)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-10-23T13:59:02.180189Z","iopub.execute_input":"2024-10-23T13:59:02.180724Z","iopub.status.idle":"2024-10-23T13:59:04.845194Z","shell.execute_reply.started":"2024-10-23T13:59:02.180675Z","shell.execute_reply":"2024-10-23T13:59:04.843843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 7. Configuration de l'augmentation d'images\ndatagen = ImageDataGenerator(\n    rotation_range=40,          # Rotation aléatoire jusqu'à 40 degrés\n    width_shift_range=0.2,      # Translation horizontale jusqu'à 20% de l'image\n    height_shift_range=0.2,     # Translation verticale jusqu'à 20% de l'image\n    shear_range=0.2,            # Transformation en cisaillement\n    zoom_range=0.2,             # Zoom aléatoire jusqu'à 20%\n    horizontal_flip=True,       # Flip horizontal des images\n    fill_mode='nearest'         # Remplir les pixels vides après les transformations\n)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-10-23T13:59:08.421573Z","iopub.execute_input":"2024-10-23T13:59:08.422143Z","iopub.status.idle":"2024-10-23T13:59:08.429640Z","shell.execute_reply.started":"2024-10-23T13:59:08.422092Z","shell.execute_reply":"2024-10-23T13:59:08.428081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 8. Visualisation d'images augmentées\ndef augment_and_plot_image(category=\"10dt\", image_index=0):\n    # Charger une image de la catégorie\n    img_path = os.path.join(dataset_path, category, os.listdir(os.path.join(dataset_path, category))[image_index])\n    img = load_img(img_path)  # Charger l'image d'origine\n    img_array = img_to_array(img)  # Convertir en tableau numpy\n\n    # Redimensionner l'image pour correspondre aux besoins du modèle (facultatif)\n    img_array = img_array.reshape((1,) + img_array.shape)  # Reshape pour correspondre à ImageDataGenerator\n\n    # Créer un plot pour visualiser 5 images augmentées\n    plt.figure(figsize=(12, 12))\n    i = 0\n    for batch in datagen.flow(img_array, batch_size=1):  # Générer des images augmentées\n        plt.subplot(3, 3, i + 1)\n        plt.imshow(batch[0].astype('uint8'))  # Afficher l'image générée\n        plt.axis('off')\n        i += 1\n        if i % 9 == 0:  # Afficher 9 images\n            break\n    plt.show()\n\n# Tester l'augmentation sur une image\naugment_and_plot_image(category=\"10dt\", image_index=0)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-23T13:59:17.696838Z","iopub.execute_input":"2024-10-23T13:59:17.697348Z","iopub.status.idle":"2024-10-23T14:00:08.678527Z","shell.execute_reply.started":"2024-10-23T13:59:17.697301Z","shell.execute_reply":"2024-10-23T14:00:08.676796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# Chemin vers votre dataset\ndataset_path = \"/kaggle/input/tunisian-currency\"  # Remplacez par le chemin de votre dataset\ncategories = [\"5dt\", \"10dt\", \"20Dt\", \"50dt\"]\n\n# Créer une liste pour stocker les chemins d'images et leurs étiquettes\nimage_paths = []\nlabels = []\n\nfor category in categories:\n    folder_path = os.path.join(dataset_path, category)\n    for image_name in os.listdir(folder_path):\n        image_paths.append(os.path.join(folder_path, image_name))\n        labels.append(category)\n\n# Convertir les étiquettes en tableau NumPy\nlabels = np.array(labels)\n\n# Diviser les données en ensembles d'entraînement et de test\nX_train, X_test, y_train, y_test = train_test_split(image_paths, labels, test_size=0.2, random_state=42, stratify=labels)\n\n# En outre, vous pouvez diviser l'ensemble d'entraînement en un ensemble de validation\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42, stratify=y_train)\n\n# Afficher le nombre d'images dans chaque ensemble\nprint(f\"Ensemble d'entraînement: {len(X_train)} images\")\nprint(f\"Ensemble de validation: {len(X_val)} images\")\nprint(f\"Ensemble de test: {len(X_test)} images\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-23T14:01:02.115864Z","iopub.execute_input":"2024-10-23T14:01:02.116876Z","iopub.status.idle":"2024-10-23T14:01:02.700279Z","shell.execute_reply.started":"2024-10-23T14:01:02.116819Z","shell.execute_reply":"2024-10-23T14:01:02.698882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Définir un générateur de données avec des augmentations\ntrain_datagen = ImageDataGenerator(\n    rescale=1.0/255.0,  # Normaliser les images\n    rotation_range=40,  # Rotation aléatoire jusqu'à 40 degrés\n    width_shift_range=0.2,  # Translation horizontale jusqu'à 20%\n    height_shift_range=0.2,  # Translation verticale jusqu'à 20%\n    shear_range=0.2,  # Transformation en cisaillement\n    zoom_range=0.2,  # Zoom aléatoire jusqu'à 20%\n    horizontal_flip=True,  # Flip horizontal des images\n    fill_mode='nearest'  # Remplir les pixels vides après les transformations\n)\n\n# Générateur pour l'ensemble d'entraînement\ntrain_generator = train_datagen.flow_from_dataframe(\n    dataframe=pd.DataFrame({'filename': X_train, 'class': y_train}),\n    x_col='filename',\n    y_col='class',\n    target_size=(128, 128),  # Taille d'image pour le modèle\n    batch_size=32,\n    class_mode='categorical'  # Utiliser le mode catégorique pour la classification multi-classes\n)\n\n# Générateur pour l'ensemble de validation\nval_datagen = ImageDataGenerator(rescale=1.0/255.0)  # Normaliser les images\nval_generator = val_datagen.flow_from_dataframe(\n    dataframe=pd.DataFrame({'filename': X_val, 'class': y_val}),\n    x_col='filename',\n    y_col='class',\n    target_size=(128, 128),\n    batch_size=32,\n    class_mode='categorical'\n)\n\n# Générateur pour l'ensemble de test\ntest_datagen = ImageDataGenerator(rescale=1.0/255.0)  # Normaliser les images\ntest_generator = test_datagen.flow_from_dataframe(\n    dataframe=pd.DataFrame({'filename': X_test, 'class': y_test}),\n    x_col='filename',\n    y_col='class',\n    target_size=(128, 128),\n    batch_size=32,\n    class_mode='categorical'\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-23T14:04:15.057302Z","iopub.execute_input":"2024-10-23T14:04:15.057833Z","iopub.status.idle":"2024-10-23T14:04:15.392712Z","shell.execute_reply.started":"2024-10-23T14:04:15.057785Z","shell.execute_reply":"2024-10-23T14:04:15.391244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **2-Model Selection**","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.layers import Dense, Flatten\nfrom tensorflow.keras.models import Model\n\n# Specify the path to the local weights file\nweights_path = '/kaggle/input/vgg16-weights/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\n\n# Load the model without the classification layers and with local weights\nbase_model = VGG16(weights=weights_path, include_top=False, input_shape=(128, 128, 3))\n\n# Freeze the base model layers\nfor layer in base_model.layers:\n    layer.trainable = False\n\n# Add custom layers\nx = Flatten()(base_model.output)\nx = Dense(256, activation='relu')(x)\npredictions = Dense(len(categories), activation='softmax')(x)  # Ensure categories is defined\n\n# Create the model\nmodel = Model(inputs=base_model.input, outputs=predictions)\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Train the model on your dataset\nmodel.fit(train_generator, validation_data=val_generator, epochs=30)  # Adjust epochs as needed\n","metadata":{"execution":{"iopub.status.busy":"2024-10-23T14:55:36.308299Z","iopub.execute_input":"2024-10-23T14:55:36.309557Z","iopub.status.idle":"2024-10-23T15:24:26.711632Z","shell.execute_reply.started":"2024-10-23T14:55:36.309499Z","shell.execute_reply":"2024-10-23T15:24:26.709596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **3-Evaluation** ","metadata":{}},{"cell_type":"code","source":"# Évaluer le modèle\ntest_loss, test_accuracy = model.evaluate(test_generator)\nprint(f'Test accuracy: {test_accuracy:.2f}')\n","metadata":{"execution":{"iopub.status.busy":"2024-10-23T15:24:29.922438Z","iopub.execute_input":"2024-10-23T15:24:29.923086Z","iopub.status.idle":"2024-10-23T15:24:42.609780Z","shell.execute_reply.started":"2024-10-23T15:24:29.923026Z","shell.execute_reply":"2024-10-23T15:24:42.608492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Tracer la précision et la perte\nplt.figure(figsize=(12, 4))\n\n# Tracer la précision\nplt.subplot(1, 2, 1)\nplt.plot(history.history['accuracy'], label='Training Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.title('Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\n# Tracer la perte\nplt.subplot(1, 2, 2)\nplt.plot(history.history['loss'], label='Training Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.title('Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-10-23T15:24:52.296073Z","iopub.execute_input":"2024-10-23T15:24:52.296569Z","iopub.status.idle":"2024-10-23T15:24:52.889576Z","shell.execute_reply.started":"2024-10-23T15:24:52.296528Z","shell.execute_reply":"2024-10-23T15:24:52.888312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.models import load_model\n\n# Chemin vers l'image à tester\ntest_image_path = '/kaggle/input/testing-data/testing_data/5dt_test.jpg'  # Remplacez par le chemin de votre image\n\n# Charger et préparer l'image\ndef load_and_preprocess_image(img_path):\n    img = image.load_img(img_path, target_size=(128, 128))  # Redimensionner à 128x128\n    img_array = image.img_to_array(img)  # Convertir en tableau numpy\n    img_array = np.expand_dims(img_array, axis=0)  # Ajouter une dimension pour le batch\n    img_array /= 255.0  # Normaliser\n    return img_array\n\n\n\n# Préparer l'image pour la prédiction\nprocessed_image = load_and_preprocess_image(test_image_path)\n\n# Faire la prédiction\npredictions = model.predict(processed_image)\npredicted_class = np.argmax(predictions)  # Obtenir la classe prédite\n\n# Mapper la classe à l'étiquette\nclass_labels = list(train_generator.class_indices.keys())\npredicted_label = class_labels[predicted_class]  # Obtenir le nom de la classe prédite\n\n# Afficher l'image avec sa classe prédite\nimg = image.load_img(test_image_path)\nplt.imshow(img)\nplt.title(f'Predicted: {predicted_label}')\nplt.axis('off')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-10-23T15:25:02.297945Z","iopub.execute_input":"2024-10-23T15:25:02.299314Z","iopub.status.idle":"2024-10-23T15:25:02.869496Z","shell.execute_reply.started":"2024-10-23T15:25:02.299254Z","shell.execute_reply":"2024-10-23T15:25:02.868227Z"},"trusted":true},"execution_count":null,"outputs":[]}]}